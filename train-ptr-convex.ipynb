{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer networks basic implementation\n",
    "\n",
    "## Tasks\n",
    "Pick \"convex hull\"\n",
    "* [x] Generate the dataset\n",
    "* [x] Evaluation metric\n",
    "* [x] Implement the model\n",
    "* [ ] Reproduce the results from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points_and_hull(points, hull_indices, c='r'):\n",
    "    print('{} points, {} in the hull'.format(points.shape[0], hull_indices.shape[0]))\n",
    "    hull_indices = np.hstack([hull_indices, [hull_indices[0]]])\n",
    "\n",
    "    points_hull = points[hull_indices-1]\n",
    "\n",
    "    plt.scatter(points[:, 0], points[:, 1])\n",
    "    plt.plot(points_hull[:, 0], points_hull[:, 1], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = collections.namedtuple('Params', [\n",
    "    'gpu_device',\n",
    "    'batch_size', 'embedding_size', 'hiddens', 'n_lstms', 'dropout', 'bidir',\n",
    "    'lr', 'n_epochs',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    gpu_device=2,\n",
    "    \n",
    "    # Data\n",
    "    batch_size=1,\n",
    "    \n",
    "    # Training params\n",
    "    lr=1e-4,\n",
    "    n_epochs=50,\n",
    "    \n",
    "    # Model params # FIXME: NOT USED RIGHT NOW!\n",
    "    embedding_size=128,\n",
    "    hiddens=512,\n",
    "    n_lstms=2,\n",
    "    dropout=0,\n",
    "    bidir=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = params.gpu_device >= 0 and torch.cuda.is_available()\n",
    "DEVICE = params.gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ConvexHullDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### For convex hull\n",
    "# The data was generated using convex_hull_generator.py\n",
    "data = np.load('data/convex_hull.npz')\n",
    "\n",
    "data_train, data_val, data_test = data['arr_0']\n",
    "\n",
    "data_train = np.array(data_train)\n",
    "data_val = np.array(data_val)\n",
    "data_test = np.array(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ConvexHullDataset(data_train)\n",
    "dataset_val = ConvexHullDataset(data_val)\n",
    "dataset_test = ConvexHullDataset(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=params.batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = iter(dataloader_val)\n",
    "for ix in range(5):\n",
    "    batch = next(d)\n",
    "\n",
    "    plt.figure()\n",
    "    points = batch['points'][0].data.numpy()\n",
    "    inds_hull = batch['inds_hull'][0].data.numpy()\n",
    "    plot_points_and_hull(points, inds_hull)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointer_net import PointerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY RUN THE MODEL\n",
    "batch = next(iter(dataloader_val))\n",
    "points = batch['points'][0]\n",
    "inds_hull = batch['inds_hull'][0]\n",
    "\n",
    "pointers = model(points[np.newaxis, ...], 10)\n",
    "print(points.shape)\n",
    "print(pointers.shape)\n",
    "pointers.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA >= 0:\n",
    "    model.cuda(device=params.gpu_device)\n",
    "#     cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the optimizer / loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCE = torch.nn.CrossEntropyLoss()\n",
    "model_optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_str = 'test'\n",
    "\n",
    "# logging\n",
    "weights_folder = \"/opt/weights/{}\".format(model_str)\n",
    "log_folder =  '../tensorboard-logs/{}'.format(model_str)\n",
    "writer = SummaryWriter(log_folder) # writing log to tensorboard\n",
    "print('logging to: {}'.format(weights_folder))\n",
    "\n",
    "os.makedirs(weights_folder)  # MEANT TO FAIL IF IT ALREADY EXISTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 10000\n",
    "val_every = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_eval(model, batch, CCE):\n",
    "    points = Variable(batch['points'])\n",
    "    target_inds_hull = Variable(batch['inds_hull'] - 1)  # FIXME: Must append an EOS token, subtract 1 to make 0-based\n",
    "\n",
    "    if USE_CUDA:\n",
    "        points = points.cuda(params.gpu_device)\n",
    "        target_inds_hull = target_inds_hull.cuda(params.gpu_device)\n",
    "\n",
    "    # generate as many outputs as in the target sequence\n",
    "    n_outputs = len(target_inds_hull[0])\n",
    "    pointers = model(points, max_output_len=n_outputs)  # FIXME: because we don't have an EOS token. Also, makes sense during traing\n",
    "    assert n_outputs == pointers.shape[1]\n",
    "\n",
    "    loss = CCE(pointers.squeeze(), target_inds_hull.squeeze())\n",
    "    return pointers, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params.n_epochs):\n",
    "    for i_batch, train_batch in enumerate(dataloader_train):\n",
    "        iter_cntr = epoch * len(dataloader_train) + i_batch  # The overall iteration number across epochs\n",
    "\n",
    "        # Forward\n",
    "        pointers, train_loss = predict_and_eval(model, train_batch, CCE)\n",
    "\n",
    "        # Backprop\n",
    "        model_optim.zero_grad()\n",
    "        train_loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        writer.add_scalar('train.loss', iter_cntr, train_loss.data.cpu().numpy())\n",
    "        \n",
    "        # Save\n",
    "        if i_batch % save_every == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(weights_folder, '{}_{}.pt'.format(epoch, i_batch)))\n",
    "        \n",
    "        # Validation\n",
    "        if i_batch % val_every == 0:\n",
    "            plt.figure(figsize=(5, 5))\n",
    "\n",
    "            total_val_loss = 0\n",
    "            for jx, val_batch in enumerate(dataloader_val):\n",
    "                if jx == 10:\n",
    "                    break\n",
    "                pointers, val_loss = predict_and_eval(model, val_batch, CCE)\n",
    "                total_val_loss += val_loss.data.cpu().numpy()\n",
    "\n",
    "                # plot few\n",
    "                if jx < 4:\n",
    "                    plt.subplot(2, 2, jx+1)\n",
    "                    pred_indices = pointers.argmax(dim=-1).data.cpu().numpy() + 1\n",
    "                    \n",
    "                    target_indices = val_batch['inds_hull'][0].data.cpu().numpy()\n",
    "                    assert len(target_indices) == pred_indices.shape[1]\n",
    "                    print('Targets: {}, Preds: {}'.format(target_indices, pred_indices))\n",
    "                    points = val_batch['points'][0].data.cpu().numpy()\n",
    "                    plot_points_and_hull(points, pred_indices[0], c='b')\n",
    "                    plot_points_and_hull(points, target_indices, c='r--')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            writer.add_scalar('val.loss', iter_cntr, total_val_loss / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
