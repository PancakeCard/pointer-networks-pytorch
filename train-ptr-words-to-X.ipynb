{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer networks for words->fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.dataset_docschema import Dataset\n",
    "from docreader.evaluation.metrics.bbox_evaluation import calculate_iou\n",
    "from docschema.semantic import Word, Paragraph, TextLine, Section, Document, Field\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = collections.namedtuple('Params', [\n",
    "    'gpu_device',\n",
    "    'batch_size', 'embedding_size', 'hiddens', 'n_lstms', 'dropout', 'bidir',\n",
    "    'lr', 'n_epochs', 'val_every', 'save_every',\n",
    "    'target_container',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    gpu_device=1,\n",
    "    \n",
    "    # Data\n",
    "    batch_size=1,\n",
    "    \n",
    "    # MODEL SPECIFC\n",
    "    target_container=TextLine,\n",
    "    \n",
    "    # Training params\n",
    "    lr=1e-4,\n",
    "    n_epochs=50,\n",
    "    val_every=100,\n",
    "    save_every=1000,\n",
    "    \n",
    "    # Model params # FIXME: NOT USED RIGHT NOW!\n",
    "    embedding_size=128,\n",
    "    hiddens=512,\n",
    "    n_lstms=2,\n",
    "    dropout=0,\n",
    "    bidir=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = params.gpu_device >= 0 and torch.cuda.is_available()\n",
    "DEVICE = params.gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOC_TOKEN = np.array([-1, -1, -1, -1])\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"\n",
    "    Pre-processor for the \n",
    "    \"\"\"\n",
    "    def __init__(self, target_container, crop_h=500, crop_w=None, random_shuffle: bool = False):\n",
    "        self.target_container = target_container\n",
    "        self.crop_w = crop_w\n",
    "        self.crop_h = crop_h\n",
    "        self.random_shuffle = random_shuffle\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        words_and_containers = self.get_words_and_containers(doc, self.target_container)\n",
    "        final_data = self.preprocess_bboxes_pointers(words_and_containers, EOC_TOKEN)\n",
    "\n",
    "        if self.random_shuffle:\n",
    "            final_data = self.random_shuffle_sequence(final_data)\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    def _get_relative_bbox(self, bbox, start_row, start_col, h, w):\n",
    "        return (\n",
    "            max(bbox[0] - start_col, 0),\n",
    "            max(bbox[1] - start_row, 0),\n",
    "            min(bbox[2] - start_col, w),\n",
    "            min(bbox[3] - start_row, h)\n",
    "        )\n",
    "\n",
    "    def _get_random_crop(self, doc, image, crop_w=None, crop_h=500):\n",
    "        h, w = image.shape[:2]\n",
    "        if crop_w is None:\n",
    "            crop_w = w\n",
    "        if crop_h is None:\n",
    "            crop_h = h\n",
    "\n",
    "        start_row = np.random.randint(0, high=(h-crop_h+1))\n",
    "        start_col = np.random.randint(0, high=(w-crop_w+1))\n",
    "\n",
    "        # Clear the word annotations from the Document Schema\n",
    "        words = doc.filter_descendants(Word)\n",
    "\n",
    "        for word in words:\n",
    "            if word.bbox is None:\n",
    "                continue\n",
    "\n",
    "            # Remove the word if it overlaps with the region to delete\n",
    "            iou = calculate_iou(\n",
    "                predicted_bboxes=np.array([(start_col, start_row, start_col+crop_w, start_row+crop_h)]),\n",
    "                gt_bboxes=np.array([word.bbox]),\n",
    "                is_xywh=False, denominator='gt')\n",
    "\n",
    "            if iou[0][0] > 0.2:  # Don't delete the word!\n",
    "                word.bbox = self._get_relative_bbox(word.bbox, start_row, start_col, crop_h, crop_w)\n",
    "                continue\n",
    "\n",
    "            word.parent = None\n",
    "            del word\n",
    "\n",
    "        image = image[start_row: start_row+crop_h, start_col: start_col+crop_w]\n",
    "        return doc, image\n",
    "\n",
    "    def get_words_and_containers(self, doc: Document, target_container: Union[TextLine, Paragraph, Field, str]):\n",
    "        \"\"\"\n",
    "        Inputs: document and the container to generate sequences for.\n",
    "        Outputs: a dictionary containing the image, the \n",
    "\n",
    "        The image/doc gets cropped to a smaller size.\n",
    "        \"\"\"\n",
    "        if isinstance(target_container, str) and target_container not in ['key', 'value']:\n",
    "            raise ValueError('target_container doesnot have the correct type / value')\n",
    "        image = doc.rendered_image\n",
    "        if len(doc.filter_descendants(target_container)) == 0:\n",
    "            raise ValueError('The doc has no containers from the target container!')\n",
    "\n",
    "        doc, image = self._get_random_crop(doc, image, crop_w=self.crop_w, crop_h=self.crop_h)\n",
    "\n",
    "        list_containers = []\n",
    "        list_child_words = []\n",
    "\n",
    "        for el in doc.filter_descendants(target_container):\n",
    "            child_words = el.filter_descendants(Word)\n",
    "            if len(child_words) == 0:\n",
    "                continue\n",
    "            list_child_words.append(child_words)\n",
    "            list_containers.append(el)\n",
    "\n",
    "        assert len(list_child_words) == len(list_containers)\n",
    "        assert np.all(image.shape[:2] == np.array([self.crop_h, self.crop_w]))\n",
    "\n",
    "        return {\n",
    "            'containers': list_containers,\n",
    "            'words': list_child_words,\n",
    "            'image': image,\n",
    "        }\n",
    "\n",
    "    def _discretize(self, vals: np.ndarray, binv: int) -> np.ndarray:\n",
    "        maxval = max(vals)\n",
    "        bins = np.arange(0, maxval+1, binv)\n",
    "        return (np.digitize(vals, bins) - 1) * binv\n",
    "\n",
    "    def _get_sorted_bboxes_inds(self, bboxes: np.ndarray, binv=3) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Sort bounding boxes from top to bottom, left to right after discretizing the co-ordinates by binv \n",
    "        \"\"\"\n",
    "        if bboxes.shape[1] != 4:\n",
    "            raise ValueError\n",
    "\n",
    "        # FIXME: The scale might help here\n",
    "        lefts = self._discretize(bboxes[:, 0], binv)\n",
    "        tops = self._discretize(bboxes[:, 1], binv)\n",
    "\n",
    "        # The key allows us to easily implement the desired sorting\n",
    "        keys = tops * 1e5 + lefts\n",
    "        sort_inds = np.argsort(keys)\n",
    "        return sort_inds\n",
    "\n",
    "    def preprocess_bboxes_pointers(self, data, EOC_TOKEN):\n",
    "        # Inputs\n",
    "        containers = data['containers']\n",
    "        child_words = data['words']\n",
    "\n",
    "        container_bboxes = np.array([el.bbox for el in containers if el.bbox is not None])\n",
    "        if len(container_bboxes) == 0:\n",
    "    #         raise ValueError('no elements in the cropped area')\n",
    "            return {'bboxes': np.array([[]]), 'pointers': np.array([]), 'image': np.array([[]]), 'is_empty': True}\n",
    "\n",
    "        sort_inds_container = self._get_sorted_bboxes_inds(container_bboxes)\n",
    "\n",
    "        all_word_bboxes = [EOC_TOKEN]  # ADD ALL THE FIXED TOKENS\n",
    "        pointer_seq = []\n",
    "\n",
    "        word_idx_start = len(all_word_bboxes)\n",
    "        for idx in sort_inds_container:  # iterate over the containers in the order top-bottom left-right\n",
    "            words = child_words[idx]\n",
    "            word_bboxes = np.vstack([word.bbox for word in words if word.bbox is not None])\n",
    "            if len(word_bboxes) == 0:\n",
    "                continue\n",
    "\n",
    "            word_bboxes = word_bboxes[self._get_sorted_bboxes_inds(word_bboxes)]\n",
    "\n",
    "            all_word_bboxes.append(word_bboxes)\n",
    "            n_words = len(word_bboxes)\n",
    "\n",
    "            # Get the indices for the words and store them as the \"pointers\"\n",
    "            pointer_seq.extend(np.arange(n_words) + word_idx_start)\n",
    "            pointer_seq.append(0)  # NOTE: 0 is the index of the fixed EOC token\n",
    "            word_idx_start += n_words\n",
    "\n",
    "        all_word_bboxes = np.vstack(all_word_bboxes).astype(np.float32)\n",
    "        pointer_seq = np.array(pointer_seq).astype(np.long)\n",
    "\n",
    "        return {\n",
    "            'bboxes': all_word_bboxes,\n",
    "            'pointers': pointer_seq,\n",
    "            'image': data['image'],\n",
    "            'is_empty': False,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def random_shuffle_sequence(datum):\n",
    "        \"\"\"\n",
    "        Randomly shuffles the input sequence and the other arrays correspondingly.\n",
    "        \"\"\"\n",
    "        is_empty = datum['is_empty']\n",
    "        if is_empty:\n",
    "            return datum\n",
    "        \n",
    "#         print('shuffling!')\n",
    "\n",
    "        bboxes, pointers = datum['bboxes'], datum['pointers']\n",
    "        n = len(bboxes)\n",
    "        \n",
    "        # Generate new \n",
    "        inds_new_order = np.arange(n)\n",
    "        np.random.shuffle(inds_new_order)\n",
    "        bboxes = bboxes[inds_new_order].squeeze()\n",
    "        \n",
    "        # map the pointers to the new indices\n",
    "        inds_reverse = np.zeros(n)\n",
    "        inds_reverse[inds_new_order] = np.arange(n)\n",
    "        new_pointers = inds_reverse[pointers].astype(np.long)\n",
    "        assert np.all(new_pointers.shape == pointers.shape)\n",
    "        \n",
    "        return {\n",
    "            'bboxes': bboxes,\n",
    "            'pointers': new_pointers,\n",
    "            'image': datum['image'],\n",
    "            'is_empty': is_empty,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader specific\n",
    "def get_padded_tensor_and_lens(list_seqs, pad_constant_value=0, n_dim=2):\n",
    "    lens = np.array([len(x) for x in list_seqs])\n",
    "    # Each sequence is an array of shape seq_len*n_dim\n",
    "    for ix in range(len(list_seqs)):\n",
    "        seq = list_seqs[ix]\n",
    "        if len(seq) == 0 or len(seq[0]) == 0:\n",
    "            list_seqs[ix] = np.zeros(n_dim, dtype=np.float32)[np.newaxis, :]\n",
    "        seq = list_seqs[ix]\n",
    "        assert len(seq.shape) == 2, 'Actual shape is: {}'.format(seq.shape)\n",
    "        assert seq.shape[1] == n_dim\n",
    "\n",
    "    max_len = max(lens)\n",
    "    data = np.array([\n",
    "        np.pad(seq, pad_width=[(0, max_len - len(seq)), (0, 0)], mode='constant', constant_values=pad_constant_value)\n",
    "        for seq in list_seqs\n",
    "    ])\n",
    "\n",
    "    return data, lens\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inds_to_take = np.array([not sample['is_empty'] for sample in batch], dtype=np.bool)\n",
    "    batch = np.array(batch)[inds_to_take]\n",
    "    assert len(batch) == sum(inds_to_take)\n",
    "    \n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "\n",
    "    sequences, lens1 = get_padded_tensor_and_lens([sample['bboxes'] for sample in batch], pad_constant_value=0, n_dim=4)\n",
    "    pointers, lens2 = get_padded_tensor_and_lens([sample['pointers'][..., np.newaxis] for sample in batch], pad_constant_value=-100, n_dim=1)\n",
    "    \n",
    "    # Sort such that the longest sequence is first. Sort the pointers to match the sequences.\n",
    "    inds_sorted_desc = np.argsort(lens1)[::-1]\n",
    "    sequences, lens1 = sequences[inds_sorted_desc, ...], lens1[inds_sorted_desc]\n",
    "    pointers, lens2 = pointers[inds_sorted_desc, ...], lens2[inds_sorted_desc]\n",
    "    \n",
    "    sequences = torch.from_numpy(sequences)\n",
    "    pointers = torch.from_numpy(pointers)\n",
    "    \n",
    "    # Get the images\n",
    "    images = np.array([sample['image'][np.newaxis, ...] for sample in batch])\n",
    "    images = images[inds_sorted_desc]\n",
    "    images = torch.from_numpy(images)\n",
    "    \n",
    "    return {\n",
    "        'sequence': sequences,\n",
    "        'sequence_lens': lens1,\n",
    "        'pointers': pointers,\n",
    "        'pointer_lens': lens2,\n",
    "        'images': images,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(params.target_container, crop_h=200, crop_w=500, random_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: specify training data\n",
    "synth_list_files = ['/opt/data/field-train-acord-20190208-large-train/synth.list']\n",
    "# dataset = Dataset(synth_list_files, adapter=lambda x: x)\n",
    "dataset_train = Dataset(synth_list_files, adapter=preprocessor)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "print('Training: {:,} total images {:,} mini batches'.format(len(dataset_train), len(dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: specify valing data\n",
    "synth_list_files = ['/opt/data/field-train-acord-20190208-large-val/synth.list']\n",
    "# dataset = Dataset(synth_list_files, adapter=lambda x: x)\n",
    "dataset_val = Dataset(synth_list_files, adapter=preprocessor)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "print('valing: {:,} total images {:,} mini batches'.format(len(dataset_val), len(dataloader_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "batch = [\n",
    "    dataset_train[0],\n",
    "    dataset_train[1],\n",
    "#     dataset_train[2],\n",
    "#     dataset_train[3],\n",
    "    {'bboxes': np.array([[]]), 'pointers': np.array([]), 'image': np.array([[]]), 'is_empty': True}\n",
    "]\n",
    "\n",
    "c = collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def _draw_bbox(ax, bbox, margin=0, color='r', linestyle='solid', fill=False, **kwargs):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "\n",
    "    x1 -= margin\n",
    "    y1 -= margin\n",
    "    w += 2*margin\n",
    "    h += 2*margin\n",
    "\n",
    "    rect = mpatches.Rectangle((x1, y1), w, h, fill=fill, color=color, linestyle=linestyle, **kwargs)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "def plot_word_bboxes_ponters(image, word_bboxes, pointers, figsize=(10, 5)):\n",
    "    colors = [\n",
    "        (1, 0, 0, 0.2),\n",
    "        (1, 1, 0, 0.2),\n",
    "        (1, 0, 1, 0.2),\n",
    "        (0.5, 0, 0, 0.2),\n",
    "        (0, 0, 0.5, 0.2),\n",
    "        (0, 0.5, 0, 0.2),\n",
    "        (0.5, 0.5, 0, 0.2),\n",
    "    ]\n",
    "\n",
    "    # Plot image\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Draw Words\n",
    "#     np.random.seed(10)\n",
    "    color = colors[np.random.randint(len(colors))]\n",
    "    for pointer in pointers:\n",
    "        bbox = word_bboxes[pointer]\n",
    "        if np.all(bbox == EOC_TOKEN):  # THE EOC token\n",
    "            color = colors[np.random.randint(len(colors))]\n",
    "            continue\n",
    "\n",
    "        bbox = word_bboxes[pointer].flatten()\n",
    "        _draw_bbox(ax, bbox, fill=True, color=color)\n",
    "        plt.text((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2, str(pointer), ha='center', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, batch in enumerate(dataloader_train):\n",
    "    if ix == 4:\n",
    "        break\n",
    "    \n",
    "    if batch is None:\n",
    "        continue\n",
    "    \n",
    "    image = batch['images'][0].data.cpu().numpy().squeeze()\n",
    "    bboxes = batch['sequence'][0].data.cpu().numpy().squeeze()\n",
    "    pointers = batch['pointers'][0].data.cpu().numpy().squeeze()\n",
    "    plot_word_bboxes_ponters(image, bboxes, pointers, figsize=(5, 10))\n",
    "#     print(bboxes)\n",
    "#     print(pointers)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader_train)\n",
    "all_pointer_inds = []\n",
    "for ix in tqdm(range(200)):\n",
    "    batch = next(data_iter)\n",
    "    if batch is None or len(batch['pointers']) == 0:\n",
    "        continue\n",
    "\n",
    "    all_pointer_inds.extend(batch['pointers'].data.numpy().flatten())\n",
    "\n",
    "all_pointer_inds = np.array(all_pointer_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pointer_inds = all_pointer_inds[all_pointer_inds != -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = np.bincount(all_pointer_inds)\n",
    "w = 1. / bc\n",
    "w /= w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual sequences can be of any length. So, add a constant probability for all the remaining numbers\n",
    "max_ind = 300\n",
    "w = np.hstack([w, [w[-1]] * (max_ind - len(w))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output definition\n",
    "\n",
    "#### Inputs\n",
    "0. Choose a sub-section of the page!\n",
    "1. Take all the words (points): just b-boxes for now, we'll add in the words later\n",
    "2. Order matters - let's always sort them top-to-bottom & left-to-right. Discretize the coordinates with some basic thresholding.\n",
    "\n",
    "#### How should the output be structured?\n",
    "1. sequence of pointers (duh!)\n",
    "2. Different containers (text-lines) must be separted by `<EOC>`\n",
    "3. The entire sequence should end with an `<EOS>`\n",
    "4. The pointers within each group must be sorted in the order: top-bottom, left-right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointer_net import PointerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(n_in=4)\n",
    "\n",
    "# SANITY RUN THE MODEL\n",
    "# batch = next(iter(dataloader_val))\n",
    "# points = batch['bboxes'][0]\n",
    "\n",
    "# pointers = model(points[np.newaxis, ...], 10)\n",
    "# print(points.shape)\n",
    "# print(pointers.shape)\n",
    "# pointers.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA >= 0:\n",
    "    model.cuda(device=params.gpu_device)\n",
    "#     cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the optimizer / loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_str = 'ptr-textline-random-one-2.00'\n",
    "\n",
    "# logging\n",
    "weights_folder = \"/opt/weights/{}\".format(model_str)\n",
    "log_folder =  '../tensorboard-logs/{}'.format(model_str)\n",
    "writer = SummaryWriter(log_folder) # writing log to tensorboard\n",
    "print('logging to: {}'.format(weights_folder))\n",
    "\n",
    "os.makedirs(weights_folder)  # MEANT TO FAIL IF IT ALREADY EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_eval(model, batch, CCE):\n",
    "    points = Variable(batch['sequence'])\n",
    "    target_pointers = Variable(batch['pointers'])  # FIXME: Must append an EOS token\n",
    "    seq_lens, target_pointer_lens = batch['sequence_lens'], batch['pointer_lens']\n",
    "\n",
    "    if USE_CUDA:\n",
    "        points = points.cuda(params.gpu_device)\n",
    "        target_pointers = target_pointers.cuda(params.gpu_device)\n",
    "\n",
    "    # generate as many outputs as in the target sequence\n",
    "    n_outputs = target_pointer_lens.max()\n",
    "    pointers = model(points, seq_lens, max_output_len=n_outputs)  # FIXME: because we don't have an EOS token. Also, makes sense during traing\n",
    "    assert n_outputs == pointers.shape[1]\n",
    "\n",
    "    n_classes = pointers.shape[-1]\n",
    "    loss = CCE(pointers.contiguous().view(-1, n_classes), target_pointers.contiguous().view(-1))\n",
    "    return pointers, loss\n",
    "\n",
    "\n",
    "def visualize(batch, pred_pointers, figsize=(10, 5)):\n",
    "    image = batch['images'].data.cpu().numpy()[0].squeeze()\n",
    "    word_bboxes = batch['sequence'].data.cpu().numpy()[0]\n",
    "    target_pointers = batch['pointers'].data.cpu().numpy()[0]\n",
    "\n",
    "    assert len(target_pointers) == pred_pointers.shape[0]\n",
    "    print('Targets: {}, Preds: {}'.format(target_pointers.flatten(), pred_pointers.flatten()))\n",
    "\n",
    "    print(\"Target\")\n",
    "    plot_word_bboxes_ponters(image, word_bboxes, target_pointers, figsize=figsize)\n",
    "    plt.show()\n",
    "    print(\"Predicted\")\n",
    "    plot_word_bboxes_ponters(image, word_bboxes, pred_pointers, figsize=figsize)\n",
    "    plt.show()\n",
    "\n",
    "def get_normalized_loss_func(pointers):\n",
    "    \"\"\"\n",
    "    Calculates loss weights based on the numbers in \"pointers\" and returns a loss function initialized with those weights.\n",
    "    \"\"\"\n",
    "    bc = np.bincount(pointers)\n",
    "    bc = 1. / bc\n",
    "    bc /= bc.sum()\n",
    "\n",
    "    weight = Variable(torch.from_numpy(bc.astype(np.float32))).cuda(DEVICE)\n",
    "    loss_func = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 10000\n",
    "val_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, i_batch = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch < params.n_epochs:\n",
    "    train_data_iter = iter(dataloader_train)\n",
    "    while i_batch < len(dataloader_train):\n",
    "        i_batch += 1\n",
    "        train_batch = next(train_data_iter)\n",
    "        iter_cntr = epoch * len(dataloader_train) + i_batch  # The overall iteration number across epochs\n",
    "\n",
    "        # This could happen because of random cropping - a better cropping strategy would help\n",
    "        if train_batch is None or len(train_batch['pointers']) == 0:\n",
    "            continue\n",
    "\n",
    "        # Forward\n",
    "        l = train_batch['pointers'].data.cpu().numpy().flatten().max()\n",
    "        weight = Variable(torch.from_numpy(w[:l+1].astype(np.float32))).cuda(DEVICE)\n",
    "        loss_func = torch.nn.CrossEntropyLoss(weight=weight, ignore_index=-100).cuda(DEVICE)\n",
    "#         loss_func = get_normalized_loss_func(train_batch['pointers'].data.cpu().numpy().flatten())\n",
    "        pointers, train_loss = predict_and_eval(model, train_batch, loss_func)\n",
    "\n",
    "        # Backprop\n",
    "        model_optim.zero_grad()\n",
    "        train_loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        writer.add_scalar('train.loss', train_loss.data.cpu().numpy(), iter_cntr)\n",
    "        \n",
    "        # Save\n",
    "        if i_batch % params.save_every == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(weights_folder, '{}_{}.pt'.format(epoch, i_batch)))\n",
    "\n",
    "        # Validation\n",
    "        if i_batch % val_every == 0:\n",
    "\n",
    "            total_val_loss = 0\n",
    "            for jx, val_batch in enumerate(dataloader_val):\n",
    "                if val_batch is None or len(val_batch['pointers']) == 0:\n",
    "                    continue\n",
    "\n",
    "                if jx == 10:\n",
    "                    break\n",
    "                l = val_batch['pointers'].data.cpu().numpy().flatten().max()\n",
    "                weight = Variable(torch.from_numpy(w[:l+1].astype(np.float32))).cuda(DEVICE)\n",
    "                loss_func = torch.nn.CrossEntropyLoss(weight=weight, ignore_index=-100).cuda(DEVICE)\n",
    "#                 loss_func = get_normalized_loss_func(val_batch['pointers'].data.cpu().numpy().flatten())\n",
    "                pointers, val_loss = predict_and_eval(model, val_batch, loss_func)\n",
    "                total_val_loss += val_loss.data.cpu().numpy()\n",
    "\n",
    "                # plot few\n",
    "                if jx < 4:\n",
    "                    pred_pointers = pointers.argmax(dim=-1).data.cpu().numpy()[0]\n",
    "                    visualize(val_batch, pred_pointers)\n",
    "\n",
    "            writer.add_scalar('val.loss', total_val_loss / 10, iter_cntr)\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
