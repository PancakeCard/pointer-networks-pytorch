{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer networks for words->fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.dataset_docschema import Dataset\n",
    "from docreader.evaluation.metrics.bbox_evaluation import calculate_iou\n",
    "from docschema.semantic import Word, Paragraph, TextLine, Section, Document, Field\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = collections.namedtuple('Params', [\n",
    "    'gpu_device',\n",
    "    'batch_size', 'embedding_size', 'hiddens', 'n_lstms', 'dropout', 'bidir',\n",
    "    'lr', 'n_epochs',\n",
    "    'target_container',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    gpu_device=1,\n",
    "    \n",
    "    # Data\n",
    "    batch_size=1,\n",
    "    \n",
    "    # MODEL SPECIFC\n",
    "    target_container=TextLine,\n",
    "    \n",
    "    # Training params\n",
    "    lr=1e-4,\n",
    "    n_epochs=50,\n",
    "    \n",
    "    # Model params # FIXME: NOT USED RIGHT NOW!\n",
    "    embedding_size=128,\n",
    "    hiddens=512,\n",
    "    n_lstms=2,\n",
    "    dropout=0,\n",
    "    bidir=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = params.gpu_device >= 0 and torch.cuda.is_available()\n",
    "DEVICE = params.gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relative_bbox(bbox, start_row, start_col, h, w):\n",
    "    return (\n",
    "        max(bbox[0] - start_col, 0),\n",
    "        max(bbox[1] - start_row, 0),\n",
    "        min(bbox[2] - start_col, w),\n",
    "        min(bbox[3] - start_row, h)\n",
    "    )\n",
    "    \n",
    "\n",
    "def get_random_crop(doc, image, crop_w=None, crop_h=500):\n",
    "    w, h = image.shape[:2]\n",
    "    if crop_w is None:\n",
    "        crop_w = w\n",
    "    if crop_h is None:\n",
    "        crop_h = h\n",
    "    \n",
    "    start_row = np.random.randint(0, high=(h-crop_h+1))\n",
    "    start_col = np.random.randint(0, high=(w-crop_w+1))\n",
    "\n",
    "    # Clear the word annotations from the Document Schema\n",
    "    words = doc.filter_descendants(Word)\n",
    "\n",
    "    for word in words:\n",
    "        if word.bbox is None:\n",
    "            continue\n",
    "\n",
    "        # Remove the word if it overlaps with the region to delete\n",
    "        iou = calculate_iou(\n",
    "            predicted_bboxes=np.array([(start_col, start_row, start_col+crop_w, start_row+crop_h)]),\n",
    "            gt_bboxes=np.array([word.bbox]),\n",
    "            is_xywh=False, denominator='gt')\n",
    "\n",
    "        if iou[0][0] > 0.2:  # Don't delete the word!\n",
    "            word.bbox = _get_relative_bbox(word.bbox, start_row, start_col, crop_h, crop_w)\n",
    "            continue\n",
    "\n",
    "        word.parent = None\n",
    "        del word\n",
    "\n",
    "    image = image[start_row: start_row+crop_h, start_col: start_col+crop_w]\n",
    "    return doc, image\n",
    "\n",
    "def get_words_and_containers(doc: Document, target_container: Union[TextLine, Paragraph, Field, str]):\n",
    "    \"\"\"\n",
    "    Inputs: document and the container to generate sequences for.\n",
    "    Outputs: a dictionary containing the image, the \n",
    "    \n",
    "    The image/doc gets cropped to a smaller size.\n",
    "    \"\"\"\n",
    "    if isinstance(target_container, str) and target_container not in ['key', 'value']:\n",
    "        raise ValueError('target_container doesnot have the correct type / value')\n",
    "    image = doc.rendered_image\n",
    "    if len(doc.filter_descendants(target_container)) == 0:\n",
    "        raise ValueError('The doc has no containers from the target container!')\n",
    "\n",
    "    doc, image = get_random_crop(doc, image, crop_w=None, crop_h=500)\n",
    "\n",
    "    list_containers = []\n",
    "    list_child_words = []\n",
    "\n",
    "    for el in doc.filter_descendants(target_container):\n",
    "        child_words = el.filter_descendants(Word)\n",
    "        if len(child_words) == 0:\n",
    "            continue\n",
    "        list_child_words.append(child_words)\n",
    "        list_containers.append(el)\n",
    "\n",
    "    assert len(list_child_words) == len(list_containers)\n",
    "\n",
    "    return {\n",
    "        'containers': list_containers,\n",
    "        'words': list_child_words,\n",
    "        'image': image,\n",
    "    }\n",
    "\n",
    "def discretize(vals: np.ndarray, binv: int) -> np.ndarray:\n",
    "    maxval = max(vals)\n",
    "    bins = np.arange(0, maxval+1, binv)\n",
    "    return (np.digitize(vals, bins) - 1) * binv\n",
    "\n",
    "assert np.all(discretize([0, 1, 2, 3, 4], 3) == [0, 0, 0, 3, 3])\n",
    "\n",
    "def get_sorted_bboxes_inds(bboxes: np.ndarray, binv=3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sort bounding boxes from top to bottom, left to right after discretizing the co-ordinates by binv \n",
    "    \"\"\"\n",
    "    if bboxes.shape[1] != 4:\n",
    "        raise ValueError\n",
    "\n",
    "    # FIXME: The scale might help here\n",
    "    lefts = discretize(bboxes[:, 0], binv)\n",
    "    tops = discretize(bboxes[:, 1], binv)\n",
    "\n",
    "    # The key allows us to easily implement the desired sorting\n",
    "    keys = tops * 1e5 + lefts\n",
    "    sort_inds = np.argsort(keys)\n",
    "    return sort_inds\n",
    "\n",
    "def preprocess_bboxes_pointers(data):\n",
    "    EOC_TOKEN = np.array([-1, -1, -1, -1])\n",
    "    # Inputs\n",
    "    containers = data['containers']\n",
    "    child_words = data['words']\n",
    "\n",
    "    container_bboxes = np.array([el.bbox for el in containers if el.bbox is not None])\n",
    "    if len(container_bboxes) == 0:\n",
    "#         raise ValueError('no elements in the cropped area')\n",
    "        return {'bboxes': [[]], 'pointers': [], 'image': []}\n",
    "        \n",
    "    sort_inds_container = get_sorted_bboxes_inds(container_bboxes)\n",
    "\n",
    "    all_word_bboxes = [EOC_TOKEN]  # ADD ALL THE FIXED TOKENS\n",
    "    pointer_seq = []\n",
    "\n",
    "    word_idx_start = len(all_word_bboxes)\n",
    "    for idx in sort_inds_container:  # iterate over the containers in the order top-bottom left-right\n",
    "        words = child_words[idx]\n",
    "        word_bboxes = np.vstack([word.bbox for word in words if word.bbox is not None])\n",
    "        if len(word_bboxes) == 0:\n",
    "            continue\n",
    "\n",
    "        word_bboxes = word_bboxes[get_sorted_bboxes_inds(word_bboxes)]\n",
    "\n",
    "        all_word_bboxes.append(word_bboxes)\n",
    "        n_words = len(word_bboxes)\n",
    "        \n",
    "        # Get the indices for the words and store them as the \"pointers\"\n",
    "        pointer_seq.extend(np.arange(n_words) + word_idx_start)\n",
    "        pointer_seq.append(0)  # NOTE: 0 is the index of the fixed EOC token\n",
    "        word_idx_start += n_words\n",
    "\n",
    "    all_word_bboxes = np.vstack(all_word_bboxes).astype(np.float32)\n",
    "    pointer_seq = np.array(pointer_seq).astype(np.long)\n",
    "\n",
    "    return {\n",
    "        'bboxes': all_word_bboxes,\n",
    "        'pointers': pointer_seq,\n",
    "        'image': data['image'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor1 = lambda x: get_words_and_containers(x, params.target_container)\n",
    "preprocessor2 = preprocess_bboxes_pointers\n",
    "preprocessor = lambda x: preprocessor2(preprocessor1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: specify training data\n",
    "synth_list_files = ['/opt/data/field-train-acord-20190208-large-train/synth.list']\n",
    "# dataset = Dataset(synth_list_files, adapter=lambda x: x)\n",
    "dataset_train = Dataset(synth_list_files, adapter=preprocessor)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=1)\n",
    "print('Training: {:,} total images {:,} mini batches'.format(len(dataset_train), len(dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: specify valing data\n",
    "synth_list_files = ['/opt/data/field-train-acord-20190208-large-val/synth.list']\n",
    "# dataset = Dataset(synth_list_files, adapter=lambda x: x)\n",
    "dataset_val = Dataset(synth_list_files, adapter=preprocessor)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=True, num_workers=1)\n",
    "print('valing: {:,} total images {:,} mini batches'.format(len(dataset_val), len(dataloader_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iter = iter(dataloader_val)\n",
    "# all_seq_lens = []\n",
    "# for ix in tqdm(range(200)):\n",
    "#     batch = next(data_iter)\n",
    "#     if len(batch['pointers']) == 0:\n",
    "#         continue\n",
    "\n",
    "#     all_seq_lens.append(len(batch['pointers'][0]))\n",
    "\n",
    "# plt.hist(all_seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def _draw_bbox(ax, bbox, margin=0, color='r', linestyle='solid', fill=False, **kwargs):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "\n",
    "    x1 -= margin\n",
    "    y1 -= margin\n",
    "    w += 2*margin\n",
    "    h += 2*margin\n",
    "\n",
    "    rect = mpatches.Rectangle((x1, y1), w, h, fill=fill, color=color, linestyle=linestyle, **kwargs)\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_bboxes_ponters(image, word_bboxes, pointers):\n",
    "    colors = [\n",
    "        (1, 0, 0, 0.2),\n",
    "        (1, 1, 0, 0.2),\n",
    "        (1, 0, 1, 0.2),\n",
    "        (0.5, 0, 0, 0.2),\n",
    "        (0, 0, 0.5, 0.2),\n",
    "        (0, 0.5, 0, 0.2),\n",
    "        (0.5, 0.5, 0, 0.2),\n",
    "    ]\n",
    "\n",
    "    # Plot image\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Draw Words\n",
    "    np.random.seed(10)\n",
    "    color = colors[np.random.randint(len(colors))]\n",
    "    for pointer in pointers:\n",
    "        if pointer == 0:  # THE EOC token\n",
    "            color = colors[np.random.randint(len(colors))]\n",
    "            continue\n",
    "\n",
    "        bbox = word_bboxes[pointer]\n",
    "        _draw_bbox(ax, bbox, fill=True, color=color)\n",
    "        plt.text((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2, str(pointer), ha='center', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output definition\n",
    "\n",
    "#### Inputs\n",
    "0. Choose a sub-section of the page!\n",
    "1. Take all the words (points): just b-boxes for now, we'll add in the words later\n",
    "2. Order matters - let's always sort them top-to-bottom & left-to-right. Discretize the coordinates with some basic thresholding.\n",
    "\n",
    "#### How should the output be structured?\n",
    "1. sequence of pointers (duh!)\n",
    "2. Different containers (text-lines) must be separted by `<EOC>`\n",
    "3. The entire sequence should end with an `<EOS>`\n",
    "4. The pointers within each group must be sorted in the order: top-bottom, left-right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointer_net import PointerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(n_in=4)\n",
    "\n",
    "# SANITY RUN THE MODEL\n",
    "batch = next(iter(dataloader_val))\n",
    "points = batch['bboxes'][0]\n",
    "\n",
    "pointers = model(points[np.newaxis, ...], 10)\n",
    "print(points.shape)\n",
    "print(pointers.shape)\n",
    "pointers.sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA >= 0:\n",
    "    model.cuda(device=params.gpu_device)\n",
    "#     cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the optimizer / loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_str = 'ptr-textline-loss-scaled-1.01'\n",
    "\n",
    "# logging\n",
    "weights_folder = \"/opt/weights/{}\".format(model_str)\n",
    "log_folder =  '../tensorboard-logs/{}'.format(model_str)\n",
    "writer = SummaryWriter(log_folder) # writing log to tensorboard\n",
    "print('logging to: {}'.format(weights_folder))\n",
    "\n",
    "os.makedirs(weights_folder)  # MEANT TO FAIL IF IT ALREADY EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_eval(model, batch, CCE):\n",
    "    points = Variable(batch['bboxes'])\n",
    "    target_pointers = Variable(batch['pointers'])  # FIXME: Must append an EOS token\n",
    "\n",
    "    if USE_CUDA:\n",
    "        points = points.cuda(params.gpu_device)\n",
    "        target_pointers = target_pointers.cuda(params.gpu_device)\n",
    "\n",
    "    # generate as many outputs as in the target sequence\n",
    "    n_outputs = len(target_pointers[0])\n",
    "    pointers = model(points, max_output_len=n_outputs)  # FIXME: because we don't have an EOS token. Also, makes sense during traing\n",
    "    assert n_outputs == pointers.shape[1]\n",
    "\n",
    "    loss = CCE(pointers.squeeze(), target_pointers.squeeze())\n",
    "    return pointers, loss\n",
    "\n",
    "\n",
    "def visualize(batch, pred_pointers):\n",
    "    image = batch['image'].data.cpu().numpy()[0]\n",
    "    word_bboxes = batch['bboxes'].data.cpu().numpy()[0]\n",
    "    target_pointers = batch['pointers'].data.cpu().numpy()[0]\n",
    "\n",
    "    assert len(target_pointers) == pred_pointers.shape[0]\n",
    "    print('Targets: {}, Preds: {}'.format(target_pointers, pred_pointers))\n",
    "\n",
    "    print(\"Target\")\n",
    "    plot_word_bboxes_ponters(image, word_bboxes, target_pointers)\n",
    "    plt.show()\n",
    "    print(\"Predicted\")\n",
    "    plot_word_bboxes_ponters(image, word_bboxes, pred_pointers)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_loss_func(pointers):\n",
    "    bc = np.bincount(pointers)\n",
    "    bc = 1. / bc\n",
    "    bc /= bc.sum()\n",
    "\n",
    "    weight = Variable(torch.from_numpy(bc.astype(np.float32))).cuda(DEVICE)\n",
    "    loss_func = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 10000\n",
    "val_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params.n_epochs):\n",
    "    for i_batch, train_batch in enumerate(dataloader_train):\n",
    "        iter_cntr = epoch * len(dataloader_train) + i_batch  # The overall iteration number across epochs\n",
    "            \n",
    "        # This could happen because of random cropping - a better cropping strategy would help\n",
    "        if len(train_batch['pointers']) == 0:\n",
    "            continue\n",
    "\n",
    "        # Forward\n",
    "        loss_func = get_normalized_loss_func(train_batch['pointers'].data.cpu().numpy().flatten())\n",
    "        pointers, train_loss = predict_and_eval(model, train_batch, loss_func)\n",
    "\n",
    "        # Backprop\n",
    "        model_optim.zero_grad()\n",
    "        train_loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        writer.add_scalar('train.loss', train_loss.data.cpu().numpy(), iter_cntr)\n",
    "        \n",
    "        # Save\n",
    "        if i_batch % save_every == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(weights_folder, '{}_{}.pt'.format(epoch, i_batch)))\n",
    "\n",
    "        # Validation\n",
    "        if i_batch % val_every == 0:\n",
    "\n",
    "            total_val_loss = 0\n",
    "            for jx, val_batch in enumerate(dataloader_val):\n",
    "                if len(val_batch['pointers']) == 0:\n",
    "                    continue\n",
    "\n",
    "                if jx == 10:\n",
    "                    break\n",
    "                loss_func = get_normalized_loss_func(val_batch['pointers'].data.cpu().numpy().flatten())\n",
    "                pointers, val_loss = predict_and_eval(model, val_batch, loss_func)\n",
    "                total_val_loss += val_loss.data.cpu().numpy()\n",
    "\n",
    "                # plot few\n",
    "                if jx < 4:\n",
    "                    pred_pointers = pointers.argmax(dim=-1).data.cpu().numpy()[0]\n",
    "                    visualize(val_batch, pred_pointers)\n",
    "\n",
    "            writer.add_scalar('val.loss', total_val_loss / 10, iter_cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
