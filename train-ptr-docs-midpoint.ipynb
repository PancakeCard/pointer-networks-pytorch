{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer networks for words->X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Dataset.dataset_docschema import Dataset\n",
    "from docreader.evaluation.metrics.bbox_evaluation import calculate_iou\n",
    "from docschema.semantic import Word, Paragraph, TextLine, Section, Document, Field\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doc_data import Preprocessor, collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = collections.namedtuple('Params', [\n",
    "    'gpu_device',\n",
    "    'batch_size', 'embedding_size', 'hiddens', 'n_lstms', 'dropout', 'bidir',\n",
    "    'lr', 'n_epochs', 'val_every', 'save_every',\n",
    "    'target_container',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    gpu_device=2,\n",
    "    \n",
    "    # Data\n",
    "    batch_size=8,\n",
    "    \n",
    "    # MODEL SPECIFC\n",
    "    target_container=TextLine,\n",
    "    \n",
    "    # Training params\n",
    "    lr=1e-4,\n",
    "    n_epochs=50,\n",
    "    val_every=100,\n",
    "    save_every=1000,\n",
    "    \n",
    "    # Model params # FIXME: NOT USED RIGHT NOW!\n",
    "    embedding_size=128,\n",
    "    hiddens=512,\n",
    "    n_lstms=2,\n",
    "    dropout=0,\n",
    "    bidir=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = params.gpu_device >= 0 and torch.cuda.is_available()\n",
    "DEVICE = params.gpu_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(params.target_container, crop_h=200, crop_w=500, random_shuffle=True, only_midpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: specify training data\n",
    "synth_list_files = ['/opt/data/field-train-acord-20190214/synth.list']\n",
    "# dataset = Dataset(synth_list_files, adapter=lambda x: x)\n",
    "dataset_train = Dataset(synth_list_files, adapter=preprocessor)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "print('Training: {:,} total images {:,} mini batches'.format(len(dataset_train), len(dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: specify valing data\n",
    "synth_list_files = ['/opt/data/field-train-acord-20190214/synth.list']\n",
    "# dataset = Dataset(synth_list_files, adapter=lambda x: x)\n",
    "dataset_val = Dataset(synth_list_files, adapter=preprocessor)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=params.batch_size, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "print('valing: {:,} total images {:,} mini batches'.format(len(dataset_val), len(dataloader_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "batch = [\n",
    "    dataset_train[0],\n",
    "    dataset_train[1],\n",
    "#     dataset_train[2],\n",
    "#     dataset_train[3],\n",
    "    {'bboxes': np.array([[]]), 'pointers': np.array([]), 'image': np.array([[]]), 'is_empty': True}\n",
    "]\n",
    "\n",
    "c = collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doc_visualize import plot_points_and_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, batch in enumerate(dataloader_train):\n",
    "    if ix == 20:\n",
    "        break\n",
    "    \n",
    "    if batch is None:\n",
    "        continue\n",
    "    \n",
    "    image = batch['images'][0].data.cpu().numpy().squeeze()\n",
    "    bboxes = batch['sequence'][0].data.cpu().numpy().squeeze()\n",
    "    pointers = batch['pointers'][0].data.cpu().numpy().squeeze()\n",
    "    scale = batch['scales'][0].data.cpu().numpy()\n",
    "#     plot_word_bboxes_ponters(image, bboxes * scale, pointers, figsize=(20, 10))\n",
    "\n",
    "    plt.figure()\n",
    "    plot_points_and_lines(bboxes, pointers, image=image, scale=scale)\n",
    "    print(pointers)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output definition\n",
    "\n",
    "#### Inputs\n",
    "0. Choose a sub-section of the page!\n",
    "1. Take all the words (points): just b-boxes for now, we'll add in the words later\n",
    "2. Order matters - let's always sort them top-to-bottom & left-to-right. Discretize the coordinates with some basic thresholding.\n",
    "\n",
    "#### How should the output be structured?\n",
    "1. sequence of pointers (duh!)\n",
    "2. Different containers (text-lines) must be separted by `<EOC>`\n",
    "3. The entire sequence should end with an `<EOS>`\n",
    "4. The pointers within each group must be sorted in the order: top-bottom, left-right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointer_net import PointerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(n_in=2)\n",
    "\n",
    "# SANITY RUN THE MODEL\n",
    "batch = next(iter(dataloader_val))\n",
    "sequence = batch['sequence']\n",
    "seq_lens = batch['sequence_lens']\n",
    "\n",
    "pointers = model(sequence, seq_lens, max_output_len=10)\n",
    "print(points.shape)\n",
    "print(pointers.shape)\n",
    "pointers.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CUDA >= 0:\n",
    "    model.cuda(device=params.gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the optimizer / loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_str = 'test-1'\n",
    "\n",
    "# logging\n",
    "weights_folder = \"/opt/weights/{}\".format(model_str)\n",
    "log_folder =  '../tensorboard-logs/{}'.format(model_str)\n",
    "writer = SummaryWriter(log_folder) # writing log to tensorboard\n",
    "print('logging to: {}'.format(weights_folder))\n",
    "\n",
    "os.makedirs(weights_folder)  # MEANT TO FAIL IF IT ALREADY EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_eval(model, batch, CCE):\n",
    "    points = Variable(batch['sequence'])\n",
    "    target_pointers = Variable(batch['pointers'])  # FIXME: Must append an EOS token\n",
    "    seq_lens, target_pointer_lens = batch['sequence_lens'], batch['pointer_lens']\n",
    "\n",
    "    if USE_CUDA:\n",
    "        points = points.cuda(params.gpu_device)\n",
    "        target_pointers = target_pointers.cuda(params.gpu_device)\n",
    "\n",
    "    # generate as many outputs as in the target sequence\n",
    "    n_outputs = target_pointer_lens.max()\n",
    "    pointers = model(points, seq_lens, max_output_len=n_outputs)  # FIXME: because we don't have an EOS token. Also, makes sense during traing\n",
    "    assert n_outputs == pointers.shape[1]\n",
    "\n",
    "    n_classes = pointers.shape[-1]\n",
    "    loss = CCE(pointers.contiguous().view(-1, n_classes), target_pointers.contiguous().view(-1))\n",
    "    return pointers, loss\n",
    "\n",
    "\n",
    "def visualize(batch, pred_pointers, figsize=(10, 5)):\n",
    "    image = batch['images'].data.cpu().numpy()[0].squeeze()\n",
    "    bboxes = batch['sequence'].data.cpu().numpy()[0].squeeze()\n",
    "    target_pointers = batch['pointers'].data.cpu().numpy()[0].squeeze()\n",
    "    scale = batch['scales'].data.cpu().numpy()[0].squeeze()\n",
    "\n",
    "    assert len(target_pointers) == pred_pointers.shape[0]\n",
    "    print('Targets: {}, Preds: {}'.format(target_pointers.flatten(), pred_pointers.flatten()))\n",
    "\n",
    "    plt.figure()\n",
    "    plot_points_and_lines(bboxes, target_pointers)  # , image=image, scale=scale)\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_points_and_lines(bboxes, pred_pointers)  # , image=image, scale=scale)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def get_normalized_loss_func(pointers):\n",
    "    \"\"\"\n",
    "    Calculates loss weights based on the numbers in \"pointers\" and returns a loss function initialized with those weights.\n",
    "    \"\"\"\n",
    "    bc = np.bincount(pointers)\n",
    "    bc = 1. / bc\n",
    "    bc /= bc.sum()\n",
    "\n",
    "    weight = Variable(torch.from_numpy(bc.astype(np.float32))).cuda(DEVICE)\n",
    "    loss_func = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 10000\n",
    "val_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, i_batch = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch < 5000:  # params.n_epochs:\n",
    "    train_data_iter = iter(dataloader_train)\n",
    "    while i_batch < len(dataloader_train):\n",
    "        i_batch += 1\n",
    "        train_batch = next(train_data_iter)\n",
    "        iter_cntr = epoch * len(dataloader_train) + i_batch  # The overall iteration number across epochs\n",
    "\n",
    "        # This could happen because of random cropping - a better cropping strategy would help\n",
    "        if train_batch is None or len(train_batch['pointers']) == 0:\n",
    "            continue\n",
    "\n",
    "        # Forward\n",
    "        l = train_batch['pointers'].data.cpu().numpy().flatten().max()\n",
    "        loss_func = torch.nn.CrossEntropyLoss(ignore_index=-100).cuda(DEVICE)\n",
    "        pointers, train_loss = predict_and_eval(model, train_batch, loss_func)\n",
    "\n",
    "        # Backprop\n",
    "        model_optim.zero_grad()\n",
    "        train_loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        writer.add_scalar('train.loss', train_loss.data.cpu().numpy(), iter_cntr)\n",
    "        \n",
    "        # Save\n",
    "        if i_batch % params.save_every == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(weights_folder, '{}_{}.pt'.format(epoch, i_batch)))\n",
    "\n",
    "        # Validation\n",
    "        if i_batch % val_every == 0:\n",
    "\n",
    "            total_val_loss = 0\n",
    "            for jx, val_batch in enumerate(dataloader_val):\n",
    "                if val_batch is None or len(val_batch['pointers']) == 0:\n",
    "                    continue\n",
    "\n",
    "                if jx == 10:\n",
    "                    break\n",
    "                l = val_batch['pointers'].data.cpu().numpy().flatten().max()\n",
    "                loss_func = torch.nn.CrossEntropyLoss(ignore_index=-100).cuda(DEVICE)\n",
    "                pointers, val_loss = predict_and_eval(model, val_batch, loss_func)\n",
    "                total_val_loss += val_loss.data.cpu().numpy()\n",
    "\n",
    "                # plot few\n",
    "                if jx < 4:\n",
    "                    pred_pointers = pointers.argmax(dim=-1).data.cpu().numpy()[0]\n",
    "                    visualize(val_batch, pred_pointers)\n",
    "\n",
    "            writer.add_scalar('val.loss', total_val_loss / 10, iter_cntr)\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
